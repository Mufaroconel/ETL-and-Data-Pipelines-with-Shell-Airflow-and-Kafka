# ETL Using Shell Scripting

Welcome to ETL Using Shell Scripting. After watching this video, you will be able to:

- Describe how shell scripting can be used to implement an ETL pipeline.
- Explain how ETL scripts or tasks can be scheduled.

Imagine a scenario that you have been tasked with: reporting the hourly average, minimum and maximum temperatures from a remote sensor that supplies the temperature on demand and feeding the results to a dashboard every minute. You are given APIs that:
- read the temperature and print it to standard output.
- load the stats to a repository which is available to a reporting tool such as a dashboard.

Here is an outline of how this can be achieved using Bash scripting:

1. **Extraction Step:**
   - Obtain a current temperature reading from the sensor using the supplied ‘get_temp’ API.
   - Append the reading to a log file, say ‘temperature.log’.
   - Buffer the last 60 readings and overwrite the log file with the buffered readings.

2. **Transformation Step:**
   - Call a program, for example, a python script called ‘get_stats.py’, which calculates the temperature stats from the 60-minute log.
   - Load the resulting stats into the reporting system using the load_stats API.
   - Stats can be used to display a live chart showing the hourly min, max, and average temperatures.

3. **Scheduling:**
   - Create a shell script called ‘Temperature_ETL.sh’.
   - Fill in task details such as extracting temperature readings, appending to log, and calling the Python script for transformation.
   - Ensure script executability by setting permissions.
   - Open the crontab editor and schedule the job to run every minute of every day.

In this video, you learned that:
- ETL pipelines can be built from basic Bash scripts.
- An ETL job can be scheduled to run by creating a cron job for your Bash script.
