# ETL Fundamentals

## Learning Objectives
After watching this video, you will be able to:
- Describe what an ETL process is
- Describe what data extraction means
- Describe what data transformation means
- Describe what data loading means
- List use cases for ETL processes

## What is an ETL Process?
- **ETL** stands for Extract, Transform, and Load.
- It is an automated data pipeline engineering methodology.
- Data is acquired and prepared for subsequent use in an analytics environment.
- Involves curating data from multiple sources, transforming it, and loading it into a new environment.

## Extraction
- Obtains or reads data from one or more sources.
- Common methods include:
  - Web scraping
  - Using APIs
- Source data can be static or streaming.

## Data Transformation
- Also known as data wrangling.
- Involves processing data to make it conform to the requirements of the target system and intended use case.
- Processes include cleaning, filtering, joining, feature engineering, and formatting.

## Data Loading
- Writing data to a new destination environment.
- Typical destinations include databases, data warehouses, and data marts.
- Goal is to make data readily available for ingestion by analytics applications.

## Use Cases for ETL Pipelines
- Digitizing analog data
- Capturing transaction history from OLTP systems
- Engineering features or KPIs
- Ingestion by dashboards
- Training and deploying machine learning models

## Summary
- ETL is an automated data pipeline methodology.
- Extraction obtains data, transformation processes it, and loading loads it into a new environment.
- ETL is used for various purposes, including making data accessible for machine learning models.

